{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049, 9)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "#test_df = pd.read_csv('test.csv')\n",
    "print(train_df.shape)\n",
    "#print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_df = train_df_.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import time, datetime, date\n",
    "\n",
    "def add_minutes_column(df):\n",
    "    \"\"\"\n",
    "    add extra column that contains only time without date information\n",
    "    for further filtering by time slot (see filter_by_timeslot())\n",
    "    \"\"\"\n",
    "    time_only = pd.to_datetime(df[\"Dates\"]).apply(lambda x: x.time())\n",
    "    # combine time with dummy date \n",
    "    df[\"Minutes\"] = time_only.apply(lambda x: datetime.combine(date(2000,3,3), x))\n",
    "    df[\"Minutes\"] = pd.to_datetime(df[\"Minutes\"])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filter_by_timeslot(df, middle_of_interval, mins):\n",
    "    \"\"\"\n",
    "    filter rows from data set that are within a time slot from \n",
    "    a the middle_of_interval\n",
    "    \n",
    "    @df:  dataframe\n",
    "    @middle_of_interval: timestamp that describes middle of the time slot\n",
    "    @minutes: size of half of time slot (in both directions)\n",
    "    \n",
    "    returns: a dataframe with data that fulfills a timeslot condition\n",
    "    \"\"\"\n",
    "\n",
    "    time_start = middle_of_interval - timedelta(minutes=mins)\n",
    "    time_end   = middle_of_interval + timedelta(minutes=mins)\n",
    "    \n",
    "\n",
    "    \n",
    "    if (time_start.day != time_end.day):\n",
    "        time_start = time_start + timedelta(days=1)\n",
    "        time_s = time_start.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        time_e = time_end.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "       \n",
    "        return df[(df[\"Minutes\"] > time_s) | (df[\"Minutes\"] <= time_e )]\n",
    "\n",
    "    else:\n",
    "        time_s = time_start.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        time_e = time_end.strftime(\"%Y-%m-%d %H:%M:%S\")  \n",
    "\n",
    "        return df[(df[\"Minutes\"] > time_s) & (df[\"Minutes\"] <= time_e )]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = add_minutes_column(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(train_df, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-03-03 00:00:00 7717\n",
      "2000-03-03 00:10:00 1338\n",
      "2000-03-03 00:20:00 921\n",
      "2000-03-03 00:30:00 1862\n",
      "2000-03-03 00:40:00 1017\n",
      "2000-03-03 00:50:00 836\n",
      "2000-03-03 01:00:00 2759\n",
      "2000-03-03 01:10:00 911\n",
      "2000-03-03 01:20:00 845\n",
      "2000-03-03 01:30:00 1567\n",
      "2000-03-03 01:40:00 975\n",
      "2000-03-03 01:50:00 832\n",
      "2000-03-03 02:00:00 2533\n",
      "2000-03-03 02:10:00 959\n",
      "2000-03-03 02:20:00 793\n",
      "2000-03-03 02:30:00 1234\n",
      "2000-03-03 02:40:00 676\n",
      "2000-03-03 02:50:00 572\n",
      "2000-03-03 03:00:00 1528\n",
      "2000-03-03 03:10:00 594\n",
      "2000-03-03 03:20:00 492\n",
      "2000-03-03 03:30:00 777\n",
      "2000-03-03 03:40:00 479\n",
      "2000-03-03 03:50:00 416\n",
      "2000-03-03 04:00:00 999\n",
      "2000-03-03 04:10:00 411\n",
      "2000-03-03 04:20:00 327\n",
      "2000-03-03 04:30:00 516\n",
      "2000-03-03 04:40:00 412\n",
      "2000-03-03 04:50:00 293\n",
      "2000-03-03 05:00:00 796\n",
      "2000-03-03 05:10:00 349\n",
      "2000-03-03 05:20:00 246\n",
      "2000-03-03 05:30:00 555\n",
      "2000-03-03 05:40:00 372\n",
      "2000-03-03 05:50:00 315\n",
      "2000-03-03 06:00:00 1160\n",
      "2000-03-03 06:10:00 389\n",
      "2000-03-03 06:20:00 335\n",
      "2000-03-03 06:30:00 810\n",
      "2000-03-03 06:40:00 592\n",
      "2000-03-03 06:50:00 496\n",
      "2000-03-03 07:00:00 1993\n",
      "2000-03-03 07:10:00 803\n",
      "2000-03-03 07:20:00 653\n",
      "2000-03-03 07:30:00 1539\n",
      "2000-03-03 07:40:00 983\n",
      "2000-03-03 07:50:00 667\n",
      "2000-03-03 08:00:00 4017\n",
      "2000-03-03 08:10:00 1045\n",
      "2000-03-03 08:20:00 840\n",
      "2000-03-03 08:30:00 2063\n",
      "2000-03-03 08:40:00 1109\n",
      "2000-03-03 08:50:00 875\n",
      "2000-03-03 09:00:00 4261\n",
      "2000-03-03 09:10:00 1133\n",
      "2000-03-03 09:20:00 970\n",
      "2000-03-03 09:30:00 2158\n",
      "2000-03-03 09:40:00 1176\n",
      "2000-03-03 09:50:00 943\n",
      "2000-03-03 10:00:00 4363\n",
      "2000-03-03 10:10:00 1291\n",
      "2000-03-03 10:20:00 1049\n",
      "2000-03-03 10:30:00 2288\n",
      "2000-03-03 10:40:00 1398\n",
      "2000-03-03 10:50:00 990\n",
      "2000-03-03 11:00:00 3851\n",
      "2000-03-03 11:10:00 1347\n",
      "2000-03-03 11:20:00 1134\n",
      "2000-03-03 11:30:00 2444\n",
      "2000-03-03 11:40:00 1550\n",
      "2000-03-03 11:50:00 1196\n",
      "2000-03-03 12:00:00 7581\n",
      "2000-03-03 12:10:00 1538\n",
      "2000-03-03 12:20:00 1157\n",
      "2000-03-03 12:30:00 2627\n",
      "2000-03-03 12:40:00 1645\n",
      "2000-03-03 12:50:00 1215\n",
      "2000-03-03 13:00:00 4565\n",
      "2000-03-03 13:10:00 1617\n",
      "2000-03-03 13:20:00 1215\n",
      "2000-03-03 13:30:00 2659\n",
      "2000-03-03 13:40:00 1679\n",
      "2000-03-03 13:50:00 1278\n",
      "2000-03-03 14:00:00 4720\n",
      "2000-03-03 14:10:00 1627\n",
      "2000-03-03 14:20:00 1294\n",
      "2000-03-03 14:30:00 2711\n",
      "2000-03-03 14:40:00 1679\n",
      "2000-03-03 14:50:00 1240\n",
      "2000-03-03 15:00:00 5298\n",
      "2000-03-03 15:10:00 1684\n",
      "2000-03-03 15:20:00 1259\n",
      "2000-03-03 15:30:00 3040\n",
      "2000-03-03 15:40:00 1833\n",
      "2000-03-03 15:50:00 1223\n",
      "2000-03-03 16:00:00 5139\n",
      "2000-03-03 16:10:00 1684\n",
      "2000-03-03 16:20:00 1506\n",
      "2000-03-03 16:30:00 3112\n",
      "2000-03-03 16:40:00 1946\n",
      "2000-03-03 16:50:00 1425\n",
      "2000-03-03 17:00:00 6004\n",
      "2000-03-03 17:10:00 1812\n",
      "2000-03-03 17:20:00 1555\n",
      "2000-03-03 17:30:00 3251\n",
      "2000-03-03 17:40:00 1878\n",
      "2000-03-03 17:50:00 1478\n",
      "2000-03-03 18:00:00 6798\n",
      "2000-03-03 18:10:00 1767\n",
      "2000-03-03 18:20:00 1391\n",
      "2000-03-03 18:30:00 3493\n",
      "2000-03-03 18:40:00 1889\n",
      "2000-03-03 18:50:00 1242\n",
      "2000-03-03 19:00:00 5693\n",
      "2000-03-03 19:10:00 1715\n",
      "2000-03-03 19:20:00 1399\n",
      "2000-03-03 19:30:00 3204\n",
      "2000-03-03 19:40:00 1682\n",
      "2000-03-03 19:50:00 1175\n",
      "2000-03-03 20:00:00 5647\n",
      "2000-03-03 20:10:00 1497\n",
      "2000-03-03 20:20:00 1123\n",
      "2000-03-03 20:30:00 2818\n",
      "2000-03-03 20:40:00 1339\n",
      "2000-03-03 20:50:00 1038\n",
      "2000-03-03 21:00:00 5186\n",
      "2000-03-03 21:10:00 1302\n",
      "2000-03-03 21:20:00 1090\n",
      "2000-03-03 21:30:00 2752\n",
      "2000-03-03 21:40:00 1503\n",
      "2000-03-03 21:50:00 1120\n",
      "2000-03-03 22:00:00 5507\n",
      "2000-03-03 22:10:00 1422\n",
      "2000-03-03 22:20:00 1221\n",
      "2000-03-03 22:30:00 2952\n",
      "2000-03-03 22:40:00 1468\n",
      "2000-03-03 22:50:00 1123\n",
      "2000-03-03 23:00:00 4861\n",
      "2000-03-03 23:10:00 1298\n",
      "2000-03-03 23:20:00 1138\n",
      "2000-03-03 23:30:00 2616\n",
      "2000-03-03 23:40:00 1430\n",
      "2000-03-03 23:50:00 1207\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from itertools import repeat\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "all_classes = ['ARSON', 'ASSAULT', 'BAD CHECKS', 'BRIBERY', 'BURGLARY',\n",
    "       'DISORDERLY CONDUCT', 'DRIVING UNDER THE INFLUENCE',\n",
    "       'DRUG/NARCOTIC', 'DRUNKENNESS', 'EMBEZZLEMENT', 'EXTORTION',\n",
    "       'FAMILY OFFENSES', 'FORGERY/COUNTERFEITING', 'FRAUD', 'GAMBLING',\n",
    "       'KIDNAPPING', 'LARCENY/THEFT', 'LIQUOR LAWS', 'LOITERING',\n",
    "       'MISSING PERSON', 'NON-CRIMINAL', 'OTHER OFFENSES',\n",
    "       'PORNOGRAPHY/OBSCENE MAT', 'PROSTITUTION', 'RECOVERED VEHICLE',\n",
    "       'ROBBERY', 'RUNAWAY', 'SECONDARY CODES', 'SEX OFFENSES FORCIBLE',\n",
    "       'SEX OFFENSES NON FORCIBLE', 'STOLEN PROPERTY', 'SUICIDE',\n",
    "       'SUSPICIOUS OCC', 'TREA', 'TRESPASS', 'VANDALISM', 'VEHICLE THEFT',\n",
    "       'WARRANTS', 'WEAPON LAWS']\n",
    "\n",
    "y_name = 'Category'\n",
    "X_names = ['X', 'Y']\n",
    "\n",
    "max_rows = len(test)\n",
    "#max_rows = 3\n",
    "#y_probs = np.zeros((max_rows, 39))\n",
    "y_probs = []\n",
    "mid_interval = datetime(2000,3,3,0)\n",
    "\n",
    "step_mins = 10\n",
    "delta_interval = timedelta(minutes=step_mins)\n",
    "half_width_train_interval_minutes = step_mins \n",
    "half_width_test_interval_minutes = step_mins//2\n",
    "\n",
    "\n",
    "num_slots = 24/ (step_mins/60)\n",
    "\n",
    "for i in range(int(num_slots)):\n",
    "    #start_time = time.time()\n",
    "    filtered_train = filter_by_timeslot(train, mid_interval, mins=half_width_train_interval_minutes)\n",
    "    #filtered_train = train\n",
    "    X_train = filtered_train[X_names]\n",
    "    y_train = filtered_train[y_name]\n",
    "    \n",
    "    filtered_test = filter_by_timeslot(test, mid_interval, mins=half_width_test_interval_minutes)\n",
    "    #filtered_test = test\n",
    "    #print(filtered_test.sort_values(by=\"Minutes\")[\"Minutes\"])\n",
    "\n",
    "    #print(filtered_test.sort_values(by=\"Minutes\")[\"Minutes\"])\n",
    "    \n",
    "    \n",
    "    X_test = filtered_test[X_names]\n",
    "    print(mid_interval, len(X_test))\n",
    "\n",
    "    \n",
    "    #print(type(X_test.index.values))\n",
    "    #print(X_test.index.values.shape)\n",
    "        \n",
    "    #print(time.time() - start_time)\n",
    "    #start_time = time.time()\n",
    "\n",
    "    \n",
    "    clf = KNeighborsClassifier(n_neighbors = 400, n_jobs=4)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    # determine the classes that were not present in the training set;\n",
    "    # the ones that were are listed in clf.classes_.\n",
    "    classes_not_trained = set(clf.classes_).symmetric_difference(all_classes)\n",
    "    #print(time.time() - start_time)\n",
    "    #start_time = time.time()\n",
    "\n",
    "    # the order of classes in predict_proba's output matches that in clf.classes_.\n",
    "    prob = clf.predict_proba(X_test)\n",
    "    #print(prob)\n",
    "    new_prob = []\n",
    "    for row in prob:\n",
    "        prob_per_class = list(zip(clf.classes_, row)) + list(zip(classes_not_trained, repeat(0.)))\n",
    "        # put the probabilities in class order\n",
    "        prob_per_class = sorted(prob_per_class)\n",
    "        new_prob.append([i[1] for i in prob_per_class])\n",
    "    new_prob = np.asarray(new_prob)\n",
    "    #print(new_prob)\n",
    "    \n",
    "    new_prob = np.c_[X_test.index.values, new_prob]\n",
    "    #print(new_prob.shape)\n",
    "\n",
    "    #print(time.time() - start_time)\n",
    "    #print()\n",
    "\n",
    "    # add prediction probabilities for current row\n",
    "    y_probs.append(new_prob)\n",
    "    \n",
    "    mid_interval += delta_interval\n",
    "    \n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_np = np.vstack(y_probs)\n",
    "y_probs_df = pd.DataFrame(data=y_probs_np[:,1:], index=y_probs_np[:,0], columns=all_classes)\n",
    "y_probs_df.sort_index(inplace=True)\n",
    "y_test = test[y_name].sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 2.8401297397213683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "#y_probs_np = np.vstack(y_probs)\n",
    "#y_probs_np.sort(axis=0)\n",
    "\n",
    "#y_test = test[y_name].sort_index()\n",
    "#y_test = test[y_name]\n",
    "\n",
    "\n",
    "score = log_loss(y_test, y_probs_df, labels=all_classes)\n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "y_probs_np = np.vstack(y_probs)\n",
    "y_probs_np.sort(axis=0)\n",
    "\n",
    "y_test = test[y_name]\n",
    "\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "\n",
    "score = log_loss(y_test, y_probs, labels=all_classes)\n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_np = np.vstack(y_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test[y_name].sort_index()\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_np.sort(axis=0)\n",
    "y_probs_np[0:3,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_np[1]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda431-py35]",
   "language": "python",
   "name": "conda-env-anaconda431-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
