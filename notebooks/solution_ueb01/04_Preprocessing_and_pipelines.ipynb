{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 1 Task 4: Preprocesing & Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this task is to examine needed steps of preprocessing and the usefulness to execute these steps within a pipeline to simplify the general processing without the need to execute each step manually with a transforming dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a) Import packages declared in ueb01 excercise 4\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# task a load breast cancer wisconsin dataset as csv after recognizing csv format ;-) See ueb01 exercise 01\n",
    "# Replace header with numerical values for slicing\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data')\n",
    "original_column_header = list(data)\n",
    "# remove header from data and reindex axis\n",
    "data.columns = range(data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>84458202</td>\n",
       "      <td>M</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>...</td>\n",
       "      <td>17.06</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>844981</td>\n",
       "      <td>M</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>...</td>\n",
       "      <td>15.49</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>84501001</td>\n",
       "      <td>M</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>...</td>\n",
       "      <td>15.09</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>845636</td>\n",
       "      <td>M</td>\n",
       "      <td>16.02</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.03299</td>\n",
       "      <td>0.03323</td>\n",
       "      <td>...</td>\n",
       "      <td>19.19</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>84610002</td>\n",
       "      <td>M</td>\n",
       "      <td>15.78</td>\n",
       "      <td>17.89</td>\n",
       "      <td>103.60</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.09710</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.09954</td>\n",
       "      <td>0.06606</td>\n",
       "      <td>...</td>\n",
       "      <td>20.42</td>\n",
       "      <td>27.28</td>\n",
       "      <td>136.50</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>0.5609</td>\n",
       "      <td>0.3965</td>\n",
       "      <td>0.18100</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.10480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>846226</td>\n",
       "      <td>M</td>\n",
       "      <td>19.17</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.20650</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>...</td>\n",
       "      <td>20.96</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.3639</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>846381</td>\n",
       "      <td>M</td>\n",
       "      <td>15.85</td>\n",
       "      <td>23.95</td>\n",
       "      <td>103.70</td>\n",
       "      <td>782.7</td>\n",
       "      <td>0.08401</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.09938</td>\n",
       "      <td>0.05364</td>\n",
       "      <td>...</td>\n",
       "      <td>16.84</td>\n",
       "      <td>27.66</td>\n",
       "      <td>112.00</td>\n",
       "      <td>876.5</td>\n",
       "      <td>0.1131</td>\n",
       "      <td>0.1924</td>\n",
       "      <td>0.2322</td>\n",
       "      <td>0.11190</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.06287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>84667401</td>\n",
       "      <td>M</td>\n",
       "      <td>13.73</td>\n",
       "      <td>22.61</td>\n",
       "      <td>93.60</td>\n",
       "      <td>578.3</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.22930</td>\n",
       "      <td>0.21280</td>\n",
       "      <td>0.08025</td>\n",
       "      <td>...</td>\n",
       "      <td>15.03</td>\n",
       "      <td>32.01</td>\n",
       "      <td>108.80</td>\n",
       "      <td>697.7</td>\n",
       "      <td>0.1651</td>\n",
       "      <td>0.7725</td>\n",
       "      <td>0.6943</td>\n",
       "      <td>0.22080</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.14310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>84799002</td>\n",
       "      <td>M</td>\n",
       "      <td>14.54</td>\n",
       "      <td>27.54</td>\n",
       "      <td>96.73</td>\n",
       "      <td>658.8</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.15950</td>\n",
       "      <td>0.16390</td>\n",
       "      <td>0.07364</td>\n",
       "      <td>...</td>\n",
       "      <td>17.46</td>\n",
       "      <td>37.13</td>\n",
       "      <td>124.10</td>\n",
       "      <td>943.2</td>\n",
       "      <td>0.1678</td>\n",
       "      <td>0.6577</td>\n",
       "      <td>0.7026</td>\n",
       "      <td>0.17120</td>\n",
       "      <td>0.4218</td>\n",
       "      <td>0.13410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  1      2      3       4       5        6        7        8   \\\n",
       "0     842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690   \n",
       "1   84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740   \n",
       "2   84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140   \n",
       "3   84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800   \n",
       "4     843786  M  12.45  15.70   82.57   477.1  0.12780  0.17000  0.15780   \n",
       "5     844359  M  18.25  19.98  119.60  1040.0  0.09463  0.10900  0.11270   \n",
       "6   84458202  M  13.71  20.83   90.20   577.9  0.11890  0.16450  0.09366   \n",
       "7     844981  M  13.00  21.82   87.50   519.8  0.12730  0.19320  0.18590   \n",
       "8   84501001  M  12.46  24.04   83.97   475.9  0.11860  0.23960  0.22730   \n",
       "9     845636  M  16.02  23.24  102.70   797.8  0.08206  0.06669  0.03299   \n",
       "10  84610002  M  15.78  17.89  103.60   781.0  0.09710  0.12920  0.09954   \n",
       "11    846226  M  19.17  24.80  132.40  1123.0  0.09740  0.24580  0.20650   \n",
       "12    846381  M  15.85  23.95  103.70   782.7  0.08401  0.10020  0.09938   \n",
       "13  84667401  M  13.73  22.61   93.60   578.3  0.11310  0.22930  0.21280   \n",
       "14  84799002  M  14.54  27.54   96.73   658.8  0.11390  0.15950  0.16390   \n",
       "\n",
       "         9    ...        22     23      24      25      26      27      28  \\\n",
       "0   0.07017   ...     24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416   \n",
       "1   0.12790   ...     23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504   \n",
       "2   0.10520   ...     14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869   \n",
       "3   0.10430   ...     22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000   \n",
       "4   0.08089   ...     15.47  23.75  103.40   741.6  0.1791  0.5249  0.5355   \n",
       "5   0.07400   ...     22.88  27.66  153.20  1606.0  0.1442  0.2576  0.3784   \n",
       "6   0.05985   ...     17.06  28.14  110.60   897.0  0.1654  0.3682  0.2678   \n",
       "7   0.09353   ...     15.49  30.73  106.20   739.3  0.1703  0.5401  0.5390   \n",
       "8   0.08543   ...     15.09  40.68   97.65   711.4  0.1853  1.0580  1.1050   \n",
       "9   0.03323   ...     19.19  33.88  123.80  1150.0  0.1181  0.1551  0.1459   \n",
       "10  0.06606   ...     20.42  27.28  136.50  1299.0  0.1396  0.5609  0.3965   \n",
       "11  0.11180   ...     20.96  29.94  151.70  1332.0  0.1037  0.3903  0.3639   \n",
       "12  0.05364   ...     16.84  27.66  112.00   876.5  0.1131  0.1924  0.2322   \n",
       "13  0.08025   ...     15.03  32.01  108.80   697.7  0.1651  0.7725  0.6943   \n",
       "14  0.07364   ...     17.46  37.13  124.10   943.2  0.1678  0.6577  0.7026   \n",
       "\n",
       "         29      30       31  \n",
       "0   0.18600  0.2750  0.08902  \n",
       "1   0.24300  0.3613  0.08758  \n",
       "2   0.25750  0.6638  0.17300  \n",
       "3   0.16250  0.2364  0.07678  \n",
       "4   0.17410  0.3985  0.12440  \n",
       "5   0.19320  0.3063  0.08368  \n",
       "6   0.15560  0.3196  0.11510  \n",
       "7   0.20600  0.4378  0.10720  \n",
       "8   0.22100  0.4366  0.20750  \n",
       "9   0.09975  0.2948  0.08452  \n",
       "10  0.18100  0.3792  0.10480  \n",
       "11  0.17670  0.3176  0.10230  \n",
       "12  0.11190  0.2809  0.06287  \n",
       "13  0.22080  0.3596  0.14310  \n",
       "14  0.17120  0.4218  0.13410  \n",
       "\n",
       "[15 rows x 32 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examining data\n",
    "#data.tail(15)\n",
    "data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568, 32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examining shape of data for slicing\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiating LabelEncoder and slicing of data into values and classification\n",
    "label_encoder = LabelEncoder()\n",
    "X = data.loc[:, 2:].values\n",
    "Y = data.loc[:, 1].values\n",
    "\n",
    "# b) encoding Malign (M) and Bengin (B) into 1 and 0\n",
    "Y = label_encoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check correct encoding\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# c) Divide dataset into training and test data (80% training  and 20% test data)\n",
    "test_size = 0.20\n",
    "rand_state = 1\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.956\n"
     ]
    }
   ],
   "source": [
    "# d) + e) Building pipeline of transformer and estimators to calculate accuracy\n",
    "standard_scaler = ('ss',StandardScaler())\n",
    "pca = ('pcs', PCA(n_components=2))\n",
    "logistic_regression = ('lr', LogisticRegression(random_state=rand_state))\n",
    "pipeline = Pipeline([standard_scaler, pca, logistic_regression])\n",
    "pipeline.fit(X_train, Y_train)\n",
    "print('Accuracy: %.3f' % pipeline.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFECV(cv=None,\n",
       "   estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "   n_jobs=1, scoring=None, step=1, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f) Switching PCA for RFECV to determine valuable feature selections and estimating max accuracy instead of the PCA step\n",
    "# Using formerly intruduces LogisticRegression classificator as estimator\n",
    "lr = logistic_regression[1]\n",
    "selector = RFECV(lr, step=1)\n",
    "selector.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.991\n"
     ]
    }
   ],
   "source": [
    "standard_scaler = ('ss',StandardScaler())\n",
    "# pca = ('pcs', PCA(n_components=2))\n",
    "logistic_regression = ('lr', LogisticRegression(random_state=rand_state))\n",
    "rfecv = RFECV(logistic_regression[1], step=1, scoring='accuracy')\n",
    "selector = ('sel', rfecv)\n",
    "pipeline = Pipeline([standard_scaler, selector, logistic_regression])\n",
    "pipeline.fit(X_train, Y_train)\n",
    "print('Accuracy: %.3f' % pipeline.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now the results of RFECV are analysed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFYCAYAAABKymUhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1992befa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest accuracy is achieved with: 24 features\n",
      "From the given 31 features named as in the original dataset:\n",
      "\n",
      "['842302', 'M', '10.38', '1001', '0.1184', '0.2776', '0.1471', '0.2419', '0.07871', '1.095', '0.9053', '153.4', '0.04904', '0.05373', '0.01587', '0.03003', '0.006193', '25.38', '17.33', '184.6', '0.1622', '0.6656', '0.7119', '0.2654']\n",
      "\n",
      "The pipeline reaches with RFECV a maximum accuracy of: 0.991228070175\n"
     ]
    }
   ],
   "source": [
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_, \"ro\")\n",
    "plt.xlabel(\"selected features\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()\n",
    "print(\"Highest accuracy is achieved with: %s features\" % rfecv.n_features_)\n",
    "\n",
    "print(\"From the given 31 features named as in the original dataset:\\n\")\n",
    "i = 0\n",
    "features = [original_column_header[i] for i, v in enumerate(rfecv.support_) if rfecv.support_[i]]\n",
    "print(features)\n",
    "accuracy = pipeline.score(X_test, Y_test)\n",
    "print(\"\\nThe pipeline reaches with RFECV a maximum accuracy of:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
